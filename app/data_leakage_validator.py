"""
ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯æ¤œè¨¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
Information Leakage ã®å®Œå…¨æ’é™¤ã‚’ç¢ºä¿

æ©Ÿèƒ½:
1. TimeSeriesSplit ã®æ™‚é–“ç¯„å›²ã®å³å¯†ãªæ¤œè¨¼
2. ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«éå»æƒ…å ±ãŒæ··åœ¨ã—ã¦ã„ãªã„ã‹ç¢ºèª
3. ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã®ãƒã‚¤ã‚¢ã‚¹æ¤œå‡º
4. æ—¥ä»˜ã®æ™‚é–“çš„é †åºæ€§ç¢ºèª
"""

import numpy as np
from typing import List, Tuple, Dict, Any
from datetime import datetime


class DataLeakageValidator:
    """ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯æ¤œè¨¼ã‚¨ãƒ³ã‚¸ãƒ³"""

    @staticmethod
    def validate_timeseries_split(
        X: np.ndarray,
        y: np.ndarray,
        race_dates: List[str],
        train_idx: np.ndarray,
        test_idx: np.ndarray
    ) -> Dict[str, Any]:
        """
        TimeSeriesSplit ã®å³å¯†ãªæ¤œè¨¼

        Args:
            X: ç‰¹å¾´é‡è¡Œåˆ—
            y: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¡Œåˆ—
            race_dates: ãƒ¬ãƒ¼ã‚¹æ—¥ä»˜ãƒªã‚¹ãƒˆ
            train_idx: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            test_idx: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

        Returns:
            æ¤œè¨¼çµæœã®è¾æ›¸
        """
        validation_result = {
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'train_date_range': None,
            'test_date_range': None,
            'time_overlap': False,
            'class_distribution_train': None,
            'class_distribution_test': None,
            'class_balance': True,
        }

        # æ—¥ä»˜ç¯„å›²ã®å–å¾—
        train_dates = [race_dates[i] for i in train_idx]
        test_dates = [race_dates[i] for i in test_idx]

        train_dates_sorted = sorted(train_dates)
        test_dates_sorted = sorted(test_dates)

        train_min = train_dates_sorted[0]
        train_max = train_dates_sorted[-1]
        test_min = test_dates_sorted[0]
        test_max = test_dates_sorted[-1]

        validation_result['train_date_range'] = (train_min, train_max)
        validation_result['test_date_range'] = (test_min, test_max)

        # 1. æ™‚é–“ç¯„å›²ã®å³å¯†ãªåˆ†é›¢ç¢ºèª
        if train_max >= test_min:
            validation_result['errors'].append(
                f"âŒ æ™‚é–“é‡è¤‡ã‚¨ãƒ©ãƒ¼: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§æ—¥ä»˜ ({train_max}) >= ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æœ€å°æ—¥ä»˜ ({test_min})"
            )
            validation_result['is_valid'] = False
            validation_result['time_overlap'] = True
        else:
            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ™‚é–“å·®ã‚’è¨ˆç®—
            try:
                train_max_dt = datetime.strptime(train_max, '%Y-%m-%d')
                test_min_dt = datetime.strptime(test_min, '%Y-%m-%d')
                days_gap = (test_min_dt - train_max_dt).days
                validation_result['days_gap'] = days_gap

                if days_gap < 0:
                    validation_result['errors'].append(
                        f"âŒ æ™‚ç³»åˆ—é †åºã‚¨ãƒ©ãƒ¼: ãƒ†ã‚¹ãƒˆæ—¥ä»˜ãŒè¨“ç·´æ—¥ä»˜ã‚ˆã‚Šå‰ã§ã™ï¼ˆ{days_gap}æ—¥ï¼‰"
                    )
                    validation_result['is_valid'] = False
                elif days_gap == 0:
                    validation_result['warnings'].append(
                        "âš ï¸ è­¦å‘Š: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒåŒã˜æ—¥ä»˜ã§ã™ã€‚æœªæ¥æƒ…å ±ãƒªãƒ¼ã‚¯ã®ãƒªã‚¹ã‚¯æœ‰ã‚Š"
                    )
                else:
                    validation_result['status'] = f"âœ… æ™‚é–“åˆ†é›¢OK: {days_gap}æ—¥é–“ã®ã‚®ãƒ£ãƒƒãƒ—"
            except ValueError:
                validation_result['warnings'].append(
                    "âš ï¸ æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒè§£æã§ãã¾ã›ã‚“ã€‚æ‰‹å‹•æ¤œè¨¼ãŒå¿…è¦"
                )

        # 2. ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã®ç¢ºèª
        y_train = y[train_idx]
        y_test = y[test_idx]

        unique_classes = np.unique(y)
        train_dist = {}
        test_dist = {}

        for cls in unique_classes:
            train_count = np.sum(y_train == cls)
            test_count = np.sum(y_test == cls)
            train_pct = train_count / len(y_train) * 100 if len(y_train) > 0 else 0
            test_pct = test_count / len(y_test) * 100 if len(y_test) > 0 else 0

            train_dist[int(cls)] = {
                'count': int(train_count),
                'percentage': round(train_pct, 2)
            }
            test_dist[int(cls)] = {
                'count': int(test_count),
                'percentage': round(test_pct, 2)
            }

        validation_result['class_distribution_train'] = train_dist
        validation_result['class_distribution_test'] = test_dist

        # ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã®ãƒã‚¤ã‚¢ã‚¹æ¤œå‡ºï¼ˆãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®ã‚¯ãƒ©ã‚¹ãŒè¨“ç·´ã‚»ãƒƒãƒˆã«ãªã„å ´åˆï¼‰
        train_classes = set(unique_classes)
        test_classes = set(np.unique(y_test))

        missing_in_train = test_classes - train_classes
        if missing_in_train:
            validation_result['errors'].append(
                f"âŒ ã‚¯ãƒ©ã‚¹ä¸è¶³ã‚¨ãƒ©ãƒ¼: ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«è¨“ç·´ã‚»ãƒƒãƒˆã«ãªã„ã‚¯ãƒ©ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {missing_in_train}"
            )
            validation_result['is_valid'] = False
        else:
            validation_result['status'] = "âœ… ã‚¯ãƒ©ã‚¹åˆ†å¸ƒOK: ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¹ãŒè¨“ç·´ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã¦ã„ã¾ã™"

        return validation_result

    @staticmethod
    def validate_cv_splits(
        X: np.ndarray,
        y: np.ndarray,
        race_dates: List[str],
        cv_splits: List[Tuple[np.ndarray, np.ndarray]]
    ) -> Dict[str, Any]:
        """
        è¤‡æ•°ã®CVåˆ†å‰²ã‚’ä¸€æ‹¬æ¤œè¨¼

        Args:
            X: ç‰¹å¾´é‡è¡Œåˆ—
            y: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¡Œåˆ—
            race_dates: ãƒ¬ãƒ¼ã‚¹æ—¥ä»˜ãƒªã‚¹ãƒˆ
            cv_splits: (train_idx, test_idx) ã®ãƒªã‚¹ãƒˆ

        Returns:
            è¤‡æ•°åˆ†å‰²ã®æ¤œè¨¼çµæœ
        """
        results = {
            'total_folds': len(cv_splits),
            'all_valid': True,
            'folds': [],
            'summary': {}
        }

        for fold_num, (train_idx, test_idx) in enumerate(cv_splits, 1):
            fold_result = DataLeakageValidator.validate_timeseries_split(
                X, y, race_dates, train_idx, test_idx
            )
            fold_result['fold_num'] = fold_num
            results['folds'].append(fold_result)

            if not fold_result['is_valid']:
                results['all_valid'] = False

        # ã‚µãƒãƒªãƒ¼
        results['summary'] = {
            'total_valid_folds': sum(1 for f in results['folds'] if f['is_valid']),
            'total_invalid_folds': sum(1 for f in results['folds'] if not f['is_valid']),
            'all_passed': results['all_valid']
        }

        return results

    @staticmethod
    def check_feature_leakage(
        feature_names: List[str],
        excluded_patterns: List[str] = None
    ) -> Dict[str, Any]:
        """
        æ©Ÿèƒ½ãƒ¬ãƒ™ãƒ«ã§ã®ãƒªãƒ¼ã‚¯æ¤œå‡º
        ï¼ˆæœªæ¥æƒ…å ±ã‚’å«ã‚€å¯èƒ½æ€§ã®ã‚ã‚‹ç‰¹å¾´é‡ã‚’è­¦å‘Šï¼‰

        Args:
            feature_names: ç‰¹å¾´é‡åã®ãƒªã‚¹ãƒˆ
            excluded_patterns: é™¤å¤–ã™ã¹ãç‰¹å¾´é‡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒªã‚¹ãƒˆ

        Returns:
            ãƒªãƒ¼ã‚¯æ¤œå‡ºçµæœ
        """
        if excluded_patterns is None:
            excluded_patterns = [
                'future',
                'next',
                'ahead',
                'forward',
                'upcoming',
                'predicted',
                'forecast'
            ]

        potential_leakage = []
        safe_features = []

        for feature in feature_names:
            feature_lower = feature.lower()
            is_suspicious = any(pattern in feature_lower for pattern in excluded_patterns)

            if is_suspicious:
                potential_leakage.append(feature)
            else:
                safe_features.append(feature)

        return {
            'safe_features_count': len(safe_features),
            'potential_leakage_count': len(potential_leakage),
            'potential_leakage_features': potential_leakage,
            'safe_features': safe_features,
            'status': 'âœ… OK' if len(potential_leakage) == 0 else 'âš ï¸ è­¦å‘Š: ç–‘ã‚ã—ã„ç‰¹å¾´é‡ãŒã‚ã‚‹'
        }

    @staticmethod
    def validate_entry_completeness(
        X: np.ndarray,
        entries_data: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ã‚¨ãƒ³ãƒˆãƒªãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§æ¤œè¨¼
        ï¼ˆç€é †ãªã—ã®é¦¬ãŒè¨“ç·´ã«å«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèªï¼‰

        Args:
            X: ç‰¹å¾´é‡è¡Œåˆ—
            entries_data: ã‚¨ãƒ³ãƒˆãƒªæƒ…å ±ã®ãƒªã‚¹ãƒˆ

        Returns:
            å®Œå…¨æ€§æ¤œè¨¼çµæœ
        """
        result = {
            'total_samples': len(X),
            'samples_with_finish_pos': 0,
            'samples_without_finish_pos': 0,
            'finish_pos_coverage': 0.0,
            'is_valid': True,
            'warnings': []
        }

        if entries_data:
            finish_pos_count = sum(1 for e in entries_data if e.get('finish_pos') is not None)
            result['samples_with_finish_pos'] = finish_pos_count
            result['samples_without_finish_pos'] = len(entries_data) - finish_pos_count
            result['finish_pos_coverage'] = (finish_pos_count / len(entries_data) * 100) if entries_data else 0

            if result['finish_pos_coverage'] < 90:
                result['warnings'].append(
                    f"âš ï¸ è­¦å‘Š: ç€é †è¨˜éŒ²ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ {result['finish_pos_coverage']:.1f}% ã§ã™ï¼ˆæ¨å¥¨: 95%ä»¥ä¸Šï¼‰"
                )
                result['is_valid'] = False

        return result

    @staticmethod
    def print_validation_report(cv_results: Dict[str, Any]) -> None:
        """æ¤œè¨¼çµæœã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›"""
        print("\n" + "="*80)
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*80)

        for fold in cv_results['folds']:
            fold_num = fold.get('fold_num', '?')
            print(f"\nã€ Fold {fold_num} ã€‘")
            print(f"  è¨“ç·´æœŸé–“: {fold['train_date_range'][0]} ï½ {fold['train_date_range'][1]}")
            print(f"  ãƒ†ã‚¹ãƒˆæœŸé–“: {fold['test_date_range'][0]} ï½ {fold['test_date_range'][1]}")

            if fold.get('days_gap') is not None:
                print(f"  æ™‚é–“ã‚®ãƒ£ãƒƒãƒ—: {fold['days_gap']}æ—¥")

            print(f"  æ¤œè¨¼çµæœ: {'âœ… OK' if fold['is_valid'] else 'âŒ NG'}")

            if fold.get('errors'):
                for error in fold['errors']:
                    print(f"    {error}")

            if fold.get('warnings'):
                for warning in fold['warnings']:
                    print(f"    {warning}")

            # ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ
            print(f"\n  ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ:")
            print(f"    è¨“ç·´: {fold['class_distribution_train']}")
            print(f"    ãƒ†ã‚¹ãƒˆ: {fold['class_distribution_test']}")

        print("\n" + "-"*80)
        print(f"ã‚µãƒãƒªãƒ¼: {cv_results['summary']['total_valid_folds']}/{cv_results['total_folds']} Fold ãŒæœ‰åŠ¹")
        print(f"å…¨ä½“åˆ¤å®š: {'âœ… åˆæ ¼' if cv_results['all_valid'] else 'âŒ ä¸åˆæ ¼'}")
        print("="*80 + "\n")
