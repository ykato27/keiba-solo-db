"""
æ”¹å–„ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
Early Stoppingã€Learning Curveã€éå­¦ç¿’è¨ºæ–­ã‚’å«ã‚€

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ prediction_model_lightgbm.py ã‚’è£œå®Œã—ã€
ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã®ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import lightgbm as lgb
    HAS_LIGHTGBM = True
except ImportError:
    HAS_LIGHTGBM = False


class ModelTrainingEnhanced:
    """æ‹¡å¼µãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚¨ãƒ³ã‚¸ãƒ³"""

    @staticmethod
    def train_with_early_stopping(
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        model_class=None,
        model_params: Dict = None,
        early_stopping_rounds: int = 50,
        verbose: bool = True
    ):
        """
        Early Stopping ä»˜ãã§ LightGBM ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´

        Args:
            X_train: è¨“ç·´ãƒ‡ãƒ¼ã‚¿
            y_train: è¨“ç·´ãƒ©ãƒ™ãƒ«
            X_val: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
            y_val: æ¤œè¨¼ãƒ©ãƒ™ãƒ«
            model_class: ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ï¼ˆLGBMClassifier or GradientBoostingClassifierï¼‰
            model_params: ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            early_stopping_rounds: Early Stopping ã®å¾…æ©Ÿãƒ©ã‚¦ãƒ³ãƒ‰æ•°
            verbose: ãƒ­ã‚°å‡ºåŠ›

        Returns:
            è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã€è¨“ç·´å±¥æ­´ã€è¨ºæ–­æƒ…å ±
        """
        if model_params is None:
            model_params = {
                'num_leaves': 31,
                'learning_rate': 0.05,
                'n_estimators': 500,  # Early Stopping ã§å‰Šæ¸›ã•ã‚Œã‚‹
                'random_state': 42,
            }

        if not HAS_LIGHTGBM:
            raise ImportError("LightGBM is required for early stopping training")

        # LightGBM ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå½¢å¼ã«å¤‰æ›
        train_data = lgb.Dataset(X_train, label=y_train)
        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

        # Early Stopping ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        callbacks = [
            lgb.early_stopping(early_stopping_rounds),
            lgb.log_evaluation(period=0) if verbose else lgb.log_evaluation(period=0)
        ]

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        booster = lgb.train(
            params=model_params,
            train_set=train_data,
            num_boost_round=model_params.get('n_estimators', 500),
            valid_sets=[val_data],
            callbacks=callbacks,
            verbose_eval=False
        )

        # è¨“ç·´å±¥æ­´ã®å–å¾—
        evals_result = booster.evals_result_

        # è¨ºæ–­æƒ…å ±
        training_history = {
            'num_rounds': booster.num_trees(),
            'train_loss': evals_result.get('training', {}).get('multi_logloss', []),
            'val_loss': evals_result.get('valid_1', {}).get('multi_logloss', []),
            'stopped_round': early_stopping_rounds,
        }

        if verbose:
            print(f"âœ… Early Stopping ã«ã‚ˆã‚Š {booster.num_trees()} ãƒ©ã‚¦ãƒ³ãƒ‰ã§è¨“ç·´å®Œäº†")
            print(f"   ï¼ˆè¨­å®š: max {model_params.get('n_estimators', 500)} ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰")

        return booster, training_history

    @staticmethod
    def analyze_learning_curve(
        train_losses: List[float],
        val_losses: List[float]
    ) -> Dict:
        """
        Learning Curve ã‚’åˆ†æã—ã¦éå­¦ç¿’ã‚’è¨ºæ–­

        Args:
            train_losses: è¨“ç·´æå¤±ã®ãƒªã‚¹ãƒˆ
            val_losses: æ¤œè¨¼æå¤±ã®ãƒªã‚¹ãƒˆ

        Returns:
            éå­¦ç¿’ã®è¨ºæ–­æƒ…å ±
        """
        if len(train_losses) < 10:
            return {
                'status': 'âš ï¸ ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³',
                'message': '10ãƒ©ã‚¦ãƒ³ãƒ‰ä»¥ä¸Šã®è¨“ç·´ãŒå¿…è¦ã§ã™'
            }

        # æœ€å¾Œã® 10% ã®ãƒ‡ãƒ¼ã‚¿ã§å‚¾å‘ã‚’ç¢ºèª
        window_size = max(5, len(train_losses) // 10)
        final_train = np.mean(train_losses[-window_size:])
        final_val = np.mean(val_losses[-window_size:])

        # åˆæœŸã¨æœ€çµ‚ã®æå¤±å·®åˆ†
        initial_train = train_losses[0]
        initial_val = val_losses[0]

        gap = final_val - final_train
        gap_trend = (val_losses[-1] - train_losses[-1]) - (val_losses[0] - train_losses[0])

        diagnosis = {
            'final_train_loss': final_train,
            'final_val_loss': final_val,
            'generalization_gap': gap,
            'gap_trend': gap_trend,
            'status': None,
            'recommendation': None
        }

        # éå­¦ç¿’åˆ¤å®š
        if gap < 0.05:
            diagnosis['status'] = 'âœ… æ­£å¸¸'
            diagnosis['recommendation'] = 'ãƒ¢ãƒ‡ãƒ«ã¯é©åˆ‡ã«æ±åŒ–ã—ã¦ã„ã‚‹'
        elif gap < 0.15:
            diagnosis['status'] = 'ğŸŸ¡ è»½å¾®ãªéå­¦ç¿’'
            diagnosis['recommendation'] = 'early_stopping_rounds ã‚’å¢—åŠ ã•ã›ã‚‹ã‹ã€æ­£å‰‡åŒ–ã‚’å¼·åŒ–'
        elif gap < 0.3:
            diagnosis['status'] = 'ğŸŸ  ä¸­ç¨‹åº¦ã®éå­¦ç¿’'
            diagnosis['recommendation'] = 'max_depth ã‚’å‰Šæ¸›ã€learning_rate ã‚’ä¸‹ã’ã‚‹ã€n_estimators ã‚’å‰Šæ¸›'
        else:
            diagnosis['status'] = 'ğŸ”´ é‡åº¦ã®éå­¦ç¿’'
            diagnosis['recommendation'] = 'ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã®è¦‹ç›´ã—ãŒå¿…é ˆ'

        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        if gap_trend > 0.01:
            diagnosis['trend'] = 'æ‚ªåŒ–å‚¾å‘ã‚ã‚Š'
        elif gap_trend < -0.01:
            diagnosis['trend'] = 'æ”¹å–„å‚¾å‘ã‚ã‚Š'
        else:
            diagnosis['trend'] = 'å®‰å®š'

        return diagnosis

    @staticmethod
    def compute_fold_wise_metrics(
        y_true_list: List[np.ndarray],
        y_pred_list: List[np.ndarray],
        y_pred_proba_list: List[np.ndarray]
    ) -> Dict:
        """
        Fold ã”ã¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—

        Args:
            y_true_list: å„ Fold ã®çœŸå€¤ãƒªã‚¹ãƒˆ
            y_pred_list: å„ Fold ã®äºˆæ¸¬å€¤ãƒªã‚¹ãƒˆ
            y_pred_proba_list: å„ Fold ã®äºˆæ¸¬ç¢ºç‡ãƒªã‚¹ãƒˆ

        Returns:
            Fold ã”ã¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        """
        fold_metrics = []

        for fold_idx, (y_true, y_pred, y_proba) in enumerate(
            zip(y_true_list, y_pred_list, y_pred_proba_list),
            start=1
        ):
            # å„ã‚¯ãƒ©ã‚¹ã”ã¨ã®ç²¾åº¦
            accuracy = accuracy_score(y_true, y_pred)
            f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)
            f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)

            # AUC-ROCï¼ˆ3ã‚¯ãƒ©ã‚¹åˆ†é¡ã®å ´åˆã¯ ovrï¼‰
            try:
                auc_score = roc_auc_score(
                    y_true, y_proba, multi_class='ovr', average='weighted', zero_division=0
                )
            except:
                auc_score = np.nan

            fold_metrics.append({
                'fold': fold_idx,
                'accuracy': accuracy,
                'f1_macro': f1_macro,
                'f1_weighted': f1_weighted,
                'auc': auc_score,
                'samples': len(y_true)
            })

        return {
            'fold_metrics': pd.DataFrame(fold_metrics),
            'mean_accuracy': np.mean([m['accuracy'] for m in fold_metrics]),
            'std_accuracy': np.std([m['accuracy'] for m in fold_metrics]),
            'mean_f1_macro': np.mean([m['f1_macro'] for m in fold_metrics]),
            'std_f1_macro': np.std([m['f1_macro'] for m in fold_metrics]),
            'mean_auc': np.mean([m['auc'] for m in fold_metrics if not np.isnan(m['auc'])]),
        }

    @staticmethod
    def generate_training_report(
        training_history: Dict,
        fold_metrics: Dict,
        learning_curve_diagnosis: Dict
    ) -> Dict:
        """
        è¨“ç·´ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            training_history: Early Stopping ã®å±¥æ­´
            fold_metrics: Fold ã”ã¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            learning_curve_diagnosis: éå­¦ç¿’è¨ºæ–­

        Returns:
            çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ
        """
        return {
            'training_summary': {
                'num_rounds': training_history.get('num_rounds'),
                'stopped_at': training_history.get('stopped_round'),
            },
            'model_performance': {
                'mean_accuracy': fold_metrics.get('mean_accuracy'),
                'std_accuracy': fold_metrics.get('std_accuracy'),
                'mean_f1': fold_metrics.get('mean_f1_macro'),
                'mean_auc': fold_metrics.get('mean_auc'),
            },
            'overfitting_diagnosis': learning_curve_diagnosis,
            'fold_details': fold_metrics.get('fold_metrics'),
            'recommendations': ModelTrainingEnhanced._generate_recommendations(
                fold_metrics, learning_curve_diagnosis
            )
        }

    @staticmethod
    def _generate_recommendations(fold_metrics: Dict, overfitting_diag: Dict) -> List[str]:
        """è¨“ç·´çµæœã‹ã‚‰æ”¹å–„æ¨å¥¨ã‚’ç”Ÿæˆ"""
        recommendations = []

        # ç²¾åº¦ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
        mean_acc = fold_metrics.get('mean_accuracy', 0)
        if mean_acc < 0.5:
            recommendations.append('ğŸ”´ ç²¾åº¦ãŒä½ã„ï¼ˆ< 50%ï¼‰ã€‚ç‰¹å¾´é‡ã®è¦‹ç›´ã—ãŒå¿…é ˆ')
        elif mean_acc < 0.6:
            recommendations.append('ğŸŸ¡ ç²¾åº¦ãŒæ”¹å–„ã®ä½™åœ°ã‚ã‚Šï¼ˆ< 60%ï¼‰ã€‚ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’æ¤œè¨')

        # éå­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
        if overfitting_diag.get('status') in ['ğŸ”´ é‡åº¦ã®éå­¦ç¿’', 'ğŸŸ  ä¸­ç¨‹åº¦ã®éå­¦ç¿’']:
            recommendations.append('ğŸ”´ éå­¦ç¿’ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«è¤‡é›‘æ€§ã‚’å‰Šæ¸›ã—ã¦ãã ã•ã„')
        elif overfitting_diag.get('status') == 'ğŸŸ¡ è»½å¾®ãªéå­¦ç¿’':
            recommendations.append('ğŸŸ¡ è»½å¾®ãªéå­¦ç¿’ã‚ã‚Šã€‚Early Stopping ãƒ©ã‚¦ãƒ³ãƒ‰ã®èª¿æ•´ã‚’æ¤œè¨')

        # åˆ†æ•£ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
        std_acc = fold_metrics.get('std_accuracy', 0)
        if std_acc > 0.1:
            recommendations.append('ğŸŸ¡ Fold é–“ã®ç²¾åº¦ã«å¤§ããªã°ã‚‰ã¤ãã‚ã‚Šã€‚ãƒ‡ãƒ¼ã‚¿ã®æ™‚ç³»åˆ—æ§‹é€ ã‚’å†ç¢ºèª')

        if not recommendations:
            recommendations.append('âœ… ãƒ¢ãƒ‡ãƒ«ã¯è‰¯å¥½ãªçŠ¶æ…‹ã§ã™')

        return recommendations
