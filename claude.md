# Claude Code ガイドライン - keiba-solo-db プロジェクト

このドキュメントは、このプロジェクトの開発を通じて学んだ教訓、ルール、失敗事例、そして判断基準をまとめたものです。

## 🎯 基本方針

1. **自律的に判断する**：細かいコマンド実行確認は不要。戦略と判断理由だけを説明する
2. **批判的に考える**：既存の決定や実装を常に疑う。改善案があれば提案する
3. **確認は最小限**：本当に必要な決定事項（方針変更、要件定義など）だけを確認する
4. **理由を明確にする**：なぜそうするのかを常に記述する

## 📋 ブランチ管理ルール

### ❌ **やってはいけないこと**
1. **feature ブランチで開発完了後、勝手に main へマージしない**
   - 失敗例：`feature/improve-prediction-model` を自動でマージ
   - 理由：ユーザー様の確認と承認を得ていない

2. **main への勝手な push をしない**
   - 失敗例：マージ後に自動で `git push origin main`
   - 理由：ユーザー様の意図に反する可能性がある

### ✅ **正しい対応フロー**
- feature ブランチで開発・テスト完了
- feature ブランチへ push
- ユーザー様に報告（何をどう改善したか、テスト結果など）
- 指示を待つ（「OK」と言われたら main へマージ）

### 📌 **判断基準**
- **feature ブランチでの開発中**：自由に commit・push（確認不要）
- **main へのマージ・push**：常にユーザー様の確認・許可を待つ（例外なし）
- **緊急バグ修正**：「main で直ちに修正が必要」という場合のみ別途相談

---

## 🚀 環境差による問題と解決策

### ❌ **よくある問題パターン**

#### パターン1：ローカル vs クラウド環境の実行コンテキスト差
```python
# ❌ 失敗した例
from app.lib import db  # ローカルでは動くが、Streamlit Cloud は動かない

# ✅ 解決
# 単純な構造にする：app/ 直下にモジュール配置
sys.path.insert(0, str(Path(__file__).parent.parent))
import db
```

**理由**：Streamlit Cloud は package structure を認識しにくい。フラット構造が安全。

#### パターン2：ファイル移動後のパス参照破損
```python
# ❌ ファイル構造が変わると壊れる
Path(__file__).parent.parent.parent  # 階層数の魔法の数字
```

**解決方法**：
1. ファイル構造を最初に決める（移動が発生しないよう設計）
2. 必要な場合は、プロジェクトルート基準の仕組みを使う
3. すべてのパス参照を grep で一括確認してから移動

### 📌 **判断基準：ファイル構造変更時**
- **小規模な追加**：新規モジュールを app/ 直下に追加（リスク低）
- **リファクタリング**：既存ファイルを移動する場合は、パス参照の全体影響を調査してから実施
- **構造変更後**：必ず全 import を確認し、ローカルとクラウドの両方でテスト

---

## 🔍 Streamlit UI 開発の注意点

### ❌ **よくある失敗：インデント エラー**

```python
# ❌ このようなコードで「馬が選択されません」という報告が来た
if selected_horse_name:
# コメント行のインデントが足りない
selected_entry = next(...)  # この行も不足
```

**実際の原因**：
- Python のインデントルールに従っていない
- Streamlit は Python のネスト構造をそのまま反映する
- ブラウザにはエラーメッセージが表示されず、UI が単に反応しなくなる

### ✅ **Streamlit UI 開発の一般ルール**

1. **条件分岐内のコードはすべてインデント**
   ```python
   if user_selects_option:
       # ここから全て4スペースインデント（例外なし）
       data = fetch_data()
       display_result(data)
   ```

2. **with ブロックも同様**
   ```python
   with st.expander("詳細"):
       # 全て4スペースインデント
       st.write("contents")
   ```

3. **デバッグ方法**：
   - エラーメッセージなしで動作しない場合、インデント を疑え
   - `python -m py_compile filename.py` でシンタックス確認
   - local での動作確認後に commit

### 📌 **判断基準：UI コード修正**
- インデント が正しいかビジュアルで確認
- 複数レベルのネストがある場合は、エディタのブレース対応機能を使う
- テストデータを入れて、ローカルで必ず動作確認

---

## 📊 機械学習モデル開発の戦略

### ✅ **最新論文から学んだ3つの原則**

#### 原則1：特徴量エンジニアリング > モデル選択
- **理由**：論文が示すように、60+個の特徴量で工夫した方が、モデル選択より効果が大きい
- **実装方針**：WHO（馬）× WHEN（距離/馬場）× RACE × ENTRY × PEDIGREE の5次元で思考
- **現在の状態**：11個 → 60+個に拡張済み。さらに追加する余地あり（1,500個の組み合わせも可能）

#### 原則2：時系列データに TimeSeriesSplit は必須
```python
# ✅ これが標準
from sklearn.model_selection import TimeSeriesSplit
tscv = TimeSeriesSplit(n_splits=3)
```

**なぜ**：train_test_split（ランダム分割）は未来情報を過去に混ぜるため、実世界では通用しない精度になる。

**批判的視点**：
- TimeSeriesSplit も完璧ではない（レース間の時間差が一定でない）
- より厳密には、「過去N日間のデータで、未来M日間を予測」という仕組みが理想
- 現在の実装で十分だが、精度が停滞したら改善を検討する

#### 原則3：複数モデルを提供する設計
```python
# LightGBM + Random Forest
# ユーザーが選択できる設計に
```

**判断基準**：
- LightGBM：複雑で精度が高いが、セットアップが必要
- Random Forest：シンプルで即動く
- 両方提供することで、ユーザーの選択肢を増やす

### ❌ **モデル開発で陥りやすい罠**

1. **訓練データ不足**
   - 着順が記録されている馬のみが訓練データになる
   - テストデータ生成で「上位3頭のみ着順記録」→「上位8頭に拡張」した理由
   - 時系列分割で3分割するなら、最低50サンプル必要

2. **特徴量の相互作用を見落とし**
   - 単純な特徴量より、掛け算・組み合わせの方が予測力が高い
   - WHO × WHEN のような複合特徴量の追加は継続すべき

3. **過学習とのバランス**
   - 特徴量を増やすと過学習リスク高まる
   - TimeSeriesSplit で検証することが重要

### 📌 **次の改善案（自分の提案）**

1. **特徴量の さらなる拡張**
   - 騎手の勝率、調教師の勝率を追加
   - 複合特徴量（体重比 × 休み期間など）
   - 季節性特徴量（月、曜日の効果）

2. **モデルアンサンブル**
   - LightGBM + XGBoost + CatBoost の3モデルの予測を平均化
   - 各モデルの予測にウェイトをつける

3. **説明可能性の向上**
   - Shapley 値で「なぜこの馬が選ばれたか」を表示
   - ユーザーの信頼度向上につながる

---

## 📈 テストデータ生成の設計

### ✅ **実装の方針と理由**

**現実的なデータ分布を使う理由**：
- モデルは訓練データの分布から学ぶ
- テストデータが非現実的だと、本番データでの予測精度がズレる
- 例：体重が [350-550kg] が自然、[100-1000kg] はゴミ

```python
# ✅ 体重：中心400kg、±150kg の分布
horse_weight = round(400.0 + random.uniform(-100, 150), 0)

# ✅ 経過日数：加重分布（7日が35%、14日が30%）
# 現実：レースは週に1回程度、前走から7-14日が多い
days_since_last_race = random.choices(
    [7, 14, 21, 28, 35],
    weights=[35, 30, 20, 10, 5]  # 実際の競馬の出走間隔
)[0]
```

### 📌 **データ量の判断基準**

| データ量 | TimeSeriesSplit 3分割 | 用途 |
|---------|----------------------|------|
| 50-100 | 可能（各Fold 15-25） | 最小限の検証 |
| 100-500 | 推奨（各Fold 30-160） | 基本的な学習 |
| 1000+ | 理想的 | 複雑なパターン学習 |

**現在の状況**：
- テストデータ投入時：3年データで約800レース × 8-14頭 = 6,400-11,200出走
- 着順記録対象：上位8頭のため、訓練サンプル数は十分

**改善可能性**：
- 5年データなら1,300レース = 10,400-18,200出走
- より複雑な特徴量を学習できる

---

## 🔧 データベーススキーマ設計の方針

### ✅ **スキーマ拡張時の判断基準**

**拡張可能な設計の実装方法**：
```sql
-- ✅ 後から列を追加しやすい設計
CREATE TABLE IF NOT EXISTS race_entries (
    entry_id INTEGER PRIMARY KEY,
    -- ... 既存列
    horse_weight REAL,           -- 後から追加
    days_since_last_race INTEGER,
    is_steeplechase INTEGER DEFAULT 0  -- DEFAULT で既存データをカバー
);
```

**なぜこの設計か**：
- NULL 許容列 or DEFAULT 値があれば、既存データが壊れない
- 新しい特徴量を後から追加できる
- マイグレーション が簡単

### ✅ **テーブル分離のルール**

1-to-Many 関係は別テーブルに：
```sql
-- ✅ 各馬は複数の血統情報を持つ
CREATE TABLE horse_pedigree (...)
CREATE TABLE horse_weight_history (...)  -- 同じ馬の複数の体重記録
```

**批判的視点**：
- 現在の設計でも動く（denormalize でも可）
- ただし、体重履歴を追跡するなら、別テーブルが正しい
- 将来の分析で「体重変化が予測に影響」を調べるときに有用

### 📌 **スキーマ変更時の判断**
- **列追加**：DEFAULT 値があれば OK、confirm 不要
- **テーブル追加**：既存テーブルに影響なければ OK、confirm 不要
- **既存列の削除**：データロスのため、必ずユーザー様に相談

---

## 📝 Streamlit・Python コード開発の実装パターン

### ✅ **Streamlit 固有パターン**

#### キャッシング（重い処理の最適化）
```python
# ✅ モデル初期化は1回だけ（ページ再読み込みで毎回再実行される Streamlit 特性を回避）
@st.cache_resource
def get_model():
    return PredictionModel()  # 1回のみ実行

# ✅ 計算結果もキャッシュ
@st.cache_data
def fetch_race_data(date):
    return queries.get_races(date)
```

**なぜ必要か**：
- Streamlit は UI イベント（ボタンクリック）のたびにページ全体を再実行
- cache がないと、モデル初期化やDB クエリが毎回実行されて遅い
- 特に `@st.cache_resource` は "session" の間、同じオブジェクトを返す

#### エラーハンドリング
```python
# ✅ ユーザーに見える形でエラー表示
try:
    model.train()
    st.success("✨ 訓練完了")
except ValueError as e:
    st.error(f"入力エラー: {e}")
except Exception as e:
    st.error(f"予期しないエラー: {e}")
    import traceback
    st.code(traceback.format_exc())  # 開発時のデバッグ用
```

**判断基準**：
- ユーザーに見せるべき情報：簡潔で分かりやすく
- 開発時のデバッグ：完全な traceback を表示

#### 長時間処理の進捗表示
```python
# ✅ ステータス表示で UX 向上
with st.status("訓練中...", expanded=True) as status:
    st.write("📊 データ構築中...")
    data = build_data()

    st.write("🤖 モデル訓練中...")
    results = model.train(data)

    status.update(label="✅ 完了!", state="complete")
st.success("訓練が完了しました")
```

### 📌 **判断基準：コード品質**
- **キャッシング必要**：DB クエリ、モデル初期化、データ構築
- **キャッシング不要**：UI 状態（selectbox の値など）、重い計算が1回なら可
- **エラー処理**：本番レベルなら except を分ける、開発中なら簡潔でも OK
- **進捗表示**：5秒以上かかる処理は必ず with st.status() で表示

---

---

## 🎯 開発プロセスの判断基準サマリー

### 自律的判断が必要な場面
| 判断事項 | 対応 | 理由 |
|---------|------|------|
| 新機能の実装方針 | 自分で判断・実装、commit & push | 技術的判断、試行錯誤が必要 |
| バグ修正（feature branch） | 自分で判断・実装、commit & push | 技術的問題の解決 |
| 既存コードの改善案 | 批判的に検討、改善案を提案・実装 | より良い実装へ |
| スキーマ列追加（DEFAULT あり） | 自分で判断・実装 | 既存データに影響なし |
| テストデータの仕様変更 | 自分で判断・実装 | ローカル環境の確認で十分 |

### ユーザー様に確認が必要な場面
| 確認事項 | 理由 |
|---------|------|
| main へのマージ | 本番環境への影響 |
| 既存列の削除 | データロス |
| 要件定義の変更 | プロジェクト方針の転換 |
| 大規模なリファクタリング | 影響範囲が大きい |
| 新しい外部ライブラリの導入 | 依存関係の増加 |

### push の基準
- **feature ブランチ**：制限なし、自由に commit・push
- **main ブランチ**：ユーザー様が git merge 実行（自分は絶対に実行しない）
- **feature → main マージの報告**：「何を実装したか」「テスト状況」を簡潔に説明

---

## 📚 このプロジェクトで得られた学び

### 競馬予測（ドメイン知識）
- 特徴量エンジニアリング > モデル選択
- TimeSeriesSplit は時系列予測の必須パターン
- 複勝予測の方が実用的

### Streamlit 開発
- ローカルとクラウドの環境差は要注意
- インデント エラーはエラーメッセージなしで失敗する
- キャッシング（cache_resource, cache_data）は性能に直結

### 一般的な開発ベストプラクティス
- ファイル構造は最初に決める（移動はリスク高）
- テストデータは現実的な分布が重要
- スキーマは拡張可能な設計を心がける

### 自分（Claude Code）の働き方
- 細かいコマンド確認は不要、自律的に判断
- 既存の実装を批判的に思考して改善案を提案
- main 接触厳禁（feature ブランチ push までが職務）

---

## 🏁 このプロジェクトの実装成果

✅ SQLite 競馬データベース（8テーブル）
✅ Streamlit マルチページ web アプリ（5ページ）
✅ リアルな分布を持つテストデータ生成（3-5年分スケール対応）
✅ 2つの機械学習モデル（Random Forest + LightGBM with TimeSeriesSplit）
✅ 60+個の複合特徴量（WHO×WHEN×RACE×ENTRY×PEDIGREE 5次元）
✅ 進捗表示・エラーハンドリング整備
✅ This claude.md 知識ドキュメント

---

**このドキュメントは生きた資料です。新しい学びや失敗があったら追記してください。**
